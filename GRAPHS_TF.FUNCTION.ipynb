{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7686b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f88a2ac",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/intro_to_graphs\n",
    "\n",
    "You create and run a graph in TensorFlow by using tf.function, either as a direct call or as a decorator. tf.function takes a regular function as input and returns a Function. A Function is a Python callable that builds TensorFlow graphs from the Python function. You use a Function in the same way as its Python equivalent\n",
    "\n",
    "`tf.function`\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/function\n",
    "\n",
    "https://www.tensorflow.org/guide/function\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/def_function.py\n",
    "\n",
    "`tracing`\n",
    "\n",
    "tensorflow.org/guide/function#tracing\n",
    "\n",
    "\n",
    "`tf.autograph`\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/autograph\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d67721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Python function.\n",
    "def a_regular_function(x, y, b):\n",
    "    x = tf.matmul(x, y)\n",
    "    x = x + b\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f19754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `a_function_that_uses_a_graph` is a TensorFlow `Function`.\n",
    "a_function_that_uses_a_graph = tf.function(a_regular_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddffcadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some tensors.\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c663b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
    "# Call a `Function` like a Python function.\n",
    "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
    "assert(orig_value == tf_function_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2f001e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# Use the decorator to make `outer_function` a `Function`.\n",
    "@tf.function\n",
    "def outer_function(x):\n",
    "  y = tf.constant([[2.0], [3.0]])\n",
    "  b = tf.constant(4.0)\n",
    "\n",
    "  return inner_function(x, y, b)\n",
    "\n",
    "# Note that the callable will create a graph that\n",
    "# includes `inner_function` as well as `outer_function`.\n",
    "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6cc440",
   "metadata": {},
   "source": [
    "Any function you write with TensorFlow will contain a mixture of built-in TF operations and Python logic, such as if-then clauses, loops, break, return, continue, and more. While TensorFlow operations are easily captured by a tf.Graph, Python-specific logic needs to undergo an extra step in order to become part of the graph. tf.function uses a library called AutoGraph (tf.autograph) to convert Python code into graph-generating code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3016a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_relu(x):\n",
    "    if tf.greater(x, 0):\n",
    "        return x\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a7cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\n",
    "tf_simple_relu = tf.function(simple_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5458d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First branch, with graph: 1\n",
      "Second branch, with graph: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
    "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e411da",
   "metadata": {},
   "source": [
    "A tf.Graph is specialized to a specific type of inputs (for example, tensors with a specific dtype or objects with the same id()).\n",
    "\n",
    "Each time you invoke a Function with new dtypes and shapes in its arguments, Function creates a new tf.Graph for the new arguments. The dtypes and shapes of a tf.Graph's inputs are known as an input signature or just a signature.\n",
    "\n",
    "The Function stores the tf.Graph corresponding to that signature in a ConcreteFunction. A ConcreteFunction is a wrapper around a tf.Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c28bcc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.5, shape=(), dtype=float32)\n",
      "tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([3. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def my_relu(x):\n",
    "  return tf.maximum(0., x)\n",
    "\n",
    "# `my_relu` creates new graphs as it observes more signatures.\n",
    "print(my_relu(tf.constant(5.5)))\n",
    "print(my_relu([1, -1]))\n",
    "print(my_relu(tf.constant([3., -3.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9877e6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(2,)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n",
      "\n",
      "my_relu(x=[1, -1])\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n",
      "\n",
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    float32 Tensor, shape=()\n"
     ]
    }
   ],
   "source": [
    "# There are three `ConcreteFunction`s (one for each graph) in `my_relu`.\n",
    "# The `ConcreteFunction` also knows the return type and shape!\n",
    "print(my_relu.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8952b1",
   "metadata": {},
   "source": [
    "**The code in a Function can be executed both eagerly and as a graph. By default, Function executes its code as a graph:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe108ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "  return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d4a3f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 3 1 3 4], shape=(5,), dtype=int32)\n",
      "tf.Tensor([8 4 5 0 9], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595a0689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f864d8",
   "metadata": {},
   "source": [
    "To verify that your Function's graph is doing the same computation as its equivalent Python function, you can make it execute eagerly with tf.config.run_functions_eagerly(True). This is a switch that turns off Function's ability to create and run graphs, instead executing the code normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "678a7b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e55d9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to set it back when you are done.\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c111bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "  print(\"Calculating MSE!\")\n",
    "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "  return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d27c14eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n"
     ]
    }
   ],
   "source": [
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ba9f3",
   "metadata": {},
   "source": [
    "Is the output surprising? get_MSE only printed once even though it was called three times.\n",
    "\n",
    "To explain, the print statement is executed when Function runs the original code in order to create the graph in a process known as \"tracing\". Tracing captures the TensorFlow operations into a graph, and print is not captured in the graph. That graph is then executed for all three calls without ever running the Python code again.\n",
    "\n",
    "As a sanity check, let's turn off graph execution to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e66c7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, globally set everything to run eagerly to force eager execution.\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "758162b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n",
      "Calculating MSE!\n",
      "Calculating MSE!\n"
     ]
    }
   ],
   "source": [
    "# Observe what is printed below.\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da089e",
   "metadata": {},
   "source": [
    "### Toggle between eager and graph execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ad3399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34019f85",
   "metadata": {},
   "source": [
    "print is a Python side effect, and there are other differences that you should be aware of when converting a function into a Function.\n",
    "\n",
    "If you would like to print values in both eager and graph execution, use tf.print instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2363377",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dd1c47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def unused_return_eager(x):\n",
    "  # Get index 1 will fail when `len(x) == 1`\n",
    "  tf.gather(x, [1]) # unused \n",
    "  return x\n",
    "\n",
    "try:\n",
    "  print(unused_return_eager(tf.constant([0.0])))\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "  # All operations are run during eager execution so an error is raised.\n",
    "  print(f'{type(e).__name__}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "427e593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18bbb9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def unused_return_graph(x):\n",
    "  tf.gather(x, [1]) # unused\n",
    "  return x\n",
    "\n",
    "# Only needed operations are run during graph exection. The error is not raised.\n",
    "print(unused_return_graph(tf.constant([0.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a148d7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cec1678",
   "metadata": {},
   "source": [
    "## Timing execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "301894ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: 2.803953739999997\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
    "\n",
    "def power(x, y):\n",
    "  result = tf.eye(10, dtype=tf.dtypes.int32)\n",
    "  for _ in range(y):\n",
    "    result = tf.matmul(x, result)\n",
    "  return result\n",
    "\n",
    "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02f0edbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution: 0.4456176969997614\n"
     ]
    }
   ],
   "source": [
    "power_as_graph = tf.function(power)\n",
    "print(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d086d35",
   "metadata": {},
   "source": [
    "### To see tracing use a print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60d8dea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def a_function_with_python_side_effect(x):\n",
    "  print(\"Tracing!\") # An eager-only side effect.\n",
    "  return x * x + tf.constant(2)\n",
    "\n",
    "# This is traced the first time.\n",
    "print(a_function_with_python_side_effect(tf.constant(2)))\n",
    "# The second time through, you won't see the side effect.\n",
    "print(a_function_with_python_side_effect(tf.constant(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "081dcd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "Tracing!\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# This retraces each time the Python argument changes,\n",
    "# as a Python argument could be an epoch count or other\n",
    "# hyperparameter.\n",
    "print(a_function_with_python_side_effect(2))\n",
    "print(a_function_with_python_side_effect(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91152b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9c920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a905dc3",
   "metadata": {},
   "source": [
    "## BETTER PERFORMANCE WITH TF.FUNCTION\n",
    "\n",
    "https://www.tensorflow.org/guide/function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf7f04f",
   "metadata": {},
   "source": [
    "A Function you define (for example by applying the @tf.function decorator) is just like a core TensorFlow operation: You can execute it eagerly; you can compute gradients; and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcc57e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function  # The decorator converts `add` into a `Function`.\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4ed52b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  result = add(v, 1.0)\n",
    "tape.gradient(result, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc386b",
   "metadata": {},
   "source": [
    "You can use Functions inside other Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54a74f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def dense_layer(x, w, b):\n",
    "  return add(tf.matmul(x, w), b)\n",
    "\n",
    "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e859f91",
   "metadata": {},
   "source": [
    "Functions can be faster than eager code, especially for graphs with many small ops. But for graphs with a few expensive ops (like convolutions), you may not see much speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bae13ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager conv: 0.0036601010006052093\n",
      "Function conv: 0.004009455999948841\n",
      "Note how there's not much difference in performance for convolutions\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "  return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1, 200, 200, 100])\n",
    "# Warm up\n",
    "conv_layer(image); conv_fn(image)\n",
    "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
    "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
    "print(\"Note how there's not much difference in performance for convolutions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be4ccb",
   "metadata": {},
   "source": [
    " For instance, Python supports polymorphism, but tf.Graph requires its inputs to have a specified data type and dimension. Or you may perform side tasks like reading command-line arguments, raising an error, or working with a more complex Python object; none of these things can run in a tf.Graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908fb1ce",
   "metadata": {},
   "source": [
    "Function bridges this gap by separating your code in two stages:\n",
    "\n",
    "1) In the first stage, referred to as \"tracing\", Function creates a new tf.Graph. Python code runs normally, but all TensorFlow operations (like adding two Tensors) are deferred: they are captured by the tf.Graph and not run.\n",
    "\n",
    "2) In the second stage, a tf.Graph which contains everything that was deferred in the first stage is run. This stage is much faster than the tracing stage.\n",
    "\n",
    "When Function does decide to trace, the tracing stage is immediately followed by the second stage, so calling the Function both creates and runs the tf.Graph\n",
    "\n",
    "When we pass arguments of different types into a Function, both stages are run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdbab8ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"a:0\", shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=float32)\n",
      "tf.Tensor(2.2, shape=(), dtype=float32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=string)\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def double(a):\n",
    "    print(\"Tracing with\", a)\n",
    "    return a + a\n",
    "\n",
    "print(double(tf.constant(1)))\n",
    "print()\n",
    "print(double(tf.constant(1.1)))\n",
    "print()\n",
    "print(double(tf.constant(\"a\")))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd8851eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double(a)\n",
      "  Args:\n",
      "    a: string Tensor, shape=()\n",
      "  Returns:\n",
      "    string Tensor, shape=()\n",
      "\n",
      "double(a)\n",
      "  Args:\n",
      "    a: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    float32 Tensor, shape=()\n",
      "\n",
      "double(a)\n",
      "  Args:\n",
      "    a: int32 Tensor, shape=()\n",
      "  Returns:\n",
      "    int32 Tensor, shape=()\n"
     ]
    }
   ],
   "source": [
    "#You can use pretty_printed_concrete_signatures() to see all of the available traces:\n",
    "print(double.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0450729d",
   "metadata": {},
   "source": [
    "### Obtaining concrete functions\n",
    "Every time a function is traced, a new concrete function is created. You can directly obtain a concrete function, by using get_concrete_function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02a525eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining concrete trace\n",
      "Executing traced function\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "tf.Tensor(b'bb', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(\"Obtaining concrete trace\")\n",
    "double_strings = double.get_concrete_function(tf.constant(\"a\"))\n",
    "print(\"Executing traced function\")\n",
    "print(double_strings(tf.constant(\"a\")))\n",
    "print(double_strings(a=tf.constant(\"b\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09b92cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction double(a)\n",
      "  Args:\n",
      "    a: string Tensor, shape=()\n",
      "  Returns:\n",
      "    string Tensor, shape=()\n"
     ]
    }
   ],
   "source": [
    "print(double_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "283738b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((TensorSpec(shape=(), dtype=tf.string, name='a'),), {})\n"
     ]
    }
   ],
   "source": [
    "print(double_strings.structured_input_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c899ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Identity:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(double_strings.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a3646fb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute __inference_double_109480 as input #0(zero-based) was expected to be a string tensor but is a int32 tensor [Op:__inference_double_109480]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6444/1985939041.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdouble_strings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mdo\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m     \"\"\"\n\u001b[1;32m-> 1669\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1676\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1677\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1678\u001b[1;33m           return self._call_with_structured_signature(args, kwargs,\n\u001b[0m\u001b[0;32m   1679\u001b[0m                                                       cancellation_manager)\n\u001b[0;32m   1680\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_with_structured_signature\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structured_signature_check_unexpected_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structured_signature_check_arg_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1759\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1760\u001b[0m         \u001b[0mfiltered_flat_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute __inference_double_109480 as input #0(zero-based) was expected to be a string tensor but is a int32 tensor [Op:__inference_double_109480]"
     ]
    }
   ],
   "source": [
    "double_strings(tf.constant(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06bc0850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"a:0\", shape=(), dtype=string)\n",
      "tf.Tensor(b'cc', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# You can also call get_concrete_function on an InputSpec\n",
    "double_strings_from_inputspec = double.get_concrete_function(tf.TensorSpec(shape=[], dtype=tf.string))\n",
    "print(double_strings_from_inputspec(tf.constant(\"c\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45120cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction double(a)\n",
      "  Args:\n",
      "    a: string Tensor, shape=()\n",
      "  Returns:\n",
      "    string Tensor, shape=()\n"
     ]
    }
   ],
   "source": [
    "print(double_strings_from_inputspec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22691c",
   "metadata": {},
   "source": [
    "#### Python arguments are given special treatment in a concrete function's input signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b080c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction pow(a, b=2)\n",
      "  Args:\n",
      "    a: float32 Tensor, shape=<unknown>\n",
      "  Returns:\n",
      "    float32 Tensor, shape=<unknown>\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def pow(a, b):\n",
    "  return a ** b\n",
    "\n",
    "square = pow.get_concrete_function(a=tf.TensorSpec(None, tf.float32), b=2)\n",
    "print(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf3f7c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=100.0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square(tf.constant(10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "165dcd8a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ConcreteFunction pow(a, b) was constructed with int value 2 in b, but was called with int value 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1681\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1682\u001b[1;33m             return self._call_with_flat_signature(args, kwargs,\n\u001b[0m\u001b[0;32m   1683\u001b[0m                                                   cancellation_manager)\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_with_flat_signature\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1726\u001b[0m               self._flat_signature_summary(), unused_key))\n\u001b[1;32m-> 1727\u001b[1;33m       raise TypeError(\"{} got unexpected keyword arguments: {}.\".format(\n\u001b[0m\u001b[0;32m   1728\u001b[0m           self._flat_signature_summary(), \", \".join(sorted(kwargs))))\n",
      "\u001b[1;31mTypeError\u001b[0m: pow(a) got unexpected keyword arguments: b.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6444/3493922769.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mdo\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m     \"\"\"\n\u001b[1;32m-> 1669\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1683\u001b[0m                                                   cancellation_manager)\n\u001b[0;32m   1684\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_with_flat_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1676\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1677\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1678\u001b[1;33m           return self._call_with_structured_signature(args, kwargs,\n\u001b[0m\u001b[0;32m   1679\u001b[0m                                                       cancellation_manager)\n\u001b[0;32m   1680\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_with_structured_signature\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1756\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structured_signature_check_missing_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structured_signature_check_unexpected_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1758\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structured_signature_check_arg_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1759\u001b[0m     return self._call_flat(\n\u001b[0;32m   1760\u001b[0m         \u001b[0mfiltered_flat_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_structured_signature_check_arg_types\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1796\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_specs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1797\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structured_signature_check_arg_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1799\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1800\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structured_signature_check_arg_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwarg_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_structured_signature_check_arg_type\u001b[1;34m(self, arg, spec, name)\u001b[0m\n\u001b[0;32m   1836\u001b[0m                   type(arg_piece).__name__, arg_piece))\n\u001b[0;32m   1837\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0marg_piece\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_BOUND_VALUE\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marg_piece\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mspec_piece\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1838\u001b[1;33m         raise TypeError(\"ConcreteFunction {} was constructed with {} value \"\n\u001b[0m\u001b[0;32m   1839\u001b[0m                         \"{} in {}, but was called with {} value {}\".format(\n\u001b[0;32m   1840\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structured_signature_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ConcreteFunction pow(a, b) was constructed with int value 2 in b, but was called with int value 3"
     ]
    }
   ],
   "source": [
    "square(tf.constant(10.0), b=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ddf110",
   "metadata": {},
   "source": [
    "#### Obtain graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16215784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] -> a\n",
      "['a', 'a'] -> add\n",
      "['add'] -> Identity\n"
     ]
    }
   ],
   "source": [
    "graph = double_strings.graph\n",
    "for node in graph.as_graph_def().node:\n",
    "  print(f'{node.input} -> {node.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8dedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8801a54f",
   "metadata": {},
   "source": [
    "## AutoGraph transformations\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#if-statements\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#while-statements\n",
    "\n",
    "AutoGraph is a library that is on by default in tf.function, and transforms a subset of Python eager code into graph-compatible TensorFlow ops. This includes control flow like if, for, while.\n",
    "\n",
    "TensorFlow ops like tf.cond and tf.while_loop continue to work, but control flow is often easier to write and understand when written in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6f73a",
   "metadata": {},
   "source": [
    "#### AutoGraph will convert some if \\<condition\\> statements into the equivalent tf.cond calls. This substitution is made if \\<condition\\> is a Tensor. Otherwise, the if statement is executed as a Python conditional.\n",
    "    \n",
    "A Python conditional executes during tracing, so exactly one branch of the conditional will be added to the graph. Without AutoGraph, this traced graph would be unable to take the alternate branch if there is data-dependent control flow.\n",
    "\n",
    "**tf.cond traces and adds both branches of the conditional to the graph, dynamically selecting a branch at execution time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e88e5",
   "metadata": {},
   "source": [
    "#### AutoGraph will convert some for and while statements into the equivalent TensorFlow looping ops, like tf.while_loop. If not converted, the for or while loop is executed as a Python loop.\n",
    "\n",
    "- for x in y: if y is a Tensor, convert to tf.while_loop. In the special case where y is a tf.data.Dataset, a combination of tf.data.Dataset ops are generated.\n",
    "- while <condition>: if <condition> is a Tensor, convert to tf.while_loop\n",
    "    \n",
    "A Python loop executes during tracing, adding additional ops to the tf.Graph for every iteration of the loop.\n",
    "\n",
    "A TensorFlow loop traces the body of the loop, and dynamically selects how many iterations to run at execution time. The loop body only appears once in the generated tf.Graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc2bb8",
   "metadata": {},
   "source": [
    "### A common pitfall is to loop over Python/NumPy data within a tf.function. This loop will execute during the tracing process, adding a copy of your model to the tf.Graph for each iteration of the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2486b668",
   "metadata": {},
   "source": [
    "### Accumulating values in a loop\n",
    "A common pattern is to accumulate intermediate values from a loop. Normally, this is accomplished by appending to a Python list or adding entries to a Python dictionary. However, as these are Python side effects, they will not work as expected in a dynamically unrolled loop. Use tf.TensorArray to accumulate results from a dynamically unrolled loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70328ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "feature_size = 4\n",
    "\n",
    "def rnn_step(inp, state):\n",
    "  return inp + state\n",
    "\n",
    "@tf.function\n",
    "def dynamic_rnn(rnn_step, input_data, initial_state):\n",
    "  # [batch, time, features] -> [time, batch, features]\n",
    "  input_data = tf.transpose(input_data, [1, 0, 2])\n",
    "  max_seq_len = input_data.shape[0]\n",
    "\n",
    "  states = tf.TensorArray(tf.float32, size=max_seq_len)\n",
    "  state = initial_state\n",
    "  for i in tf.range(max_seq_len):\n",
    "    state = rnn_step(input_data[i], state)\n",
    "    states = states.write(i, state)\n",
    "  return tf.transpose(states.stack(), [1, 0, 2])\n",
    "\n",
    "dynamic_rnn(rnn_step,\n",
    "            tf.random.uniform([batch_size, seq_len, feature_size]),\n",
    "            tf.zeros([batch_size, feature_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e6a3f",
   "metadata": {},
   "source": [
    "TensorFlow Function has a few limitations by design that you should be aware of when converting a Python function to a Function.\n",
    "\n",
    "#### Side effects, like printing, appending to lists, and mutating globals, can behave unexpectedly inside a Function, sometimes executing twice or not all. They only happen the first time you call a Function with a set of inputs. Afterwards, the traced tf.Graph is reexecuted, without executing the Python code.\n",
    "The general rule of thumb is to avoid relying on Python side effects in your logic and only use them to debug your traces. Otherwise, TensorFlow APIs like tf.data, tf.print, tf.summary, tf.Variable.assign, and tf.TensorArray are the best way to ensure your code will be executed by the TensorFlow runtime with each call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51c142",
   "metadata": {},
   "source": [
    "### Changing Python global and free variables\n",
    "Changing Python global and free variables counts as a Python side effect, so it only happens during tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a965791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python side effect\n"
     ]
    }
   ],
   "source": [
    "external_list = []\n",
    "\n",
    "@tf.function\n",
    "def side_effect(x):\n",
    "  print('Python side effect')\n",
    "  external_list.append(x)\n",
    "\n",
    "side_effect(1)\n",
    "side_effect(1)\n",
    "side_effect(1)\n",
    "# The list append only happened once!\n",
    "assert len(external_list) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bdaa0452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f13036",
   "metadata": {},
   "source": [
    "You should avoid mutating containers like lists, dicts, other objects that live outside the Function. Instead, use arguments and TF objects. For example, the section \"Accumulating values in a loop\" has one example of how list-like operations can be implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3943397",
   "metadata": {},
   "source": [
    "### Using Python iterators and generators\n",
    "Many Python features, such as generators and iterators, rely on the Python runtime to keep track of state. In general, while these constructs work as expected in eager mode, they are examples of Python side effects and therefore only happen during tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3b13334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 1\n",
      "Value: 1\n",
      "Value: 1\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_consume_next(iterator):\n",
    "  tf.print(\"Value:\", next(iterator))\n",
    "\n",
    "iterator = iter([1, 2, 3])\n",
    "buggy_consume_next(iterator)\n",
    "# This reuses the first value from the iterator, rather than consuming the next value.\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dda155",
   "metadata": {},
   "source": [
    "Just like how TensorFlow has a specialized tf.TensorArray for list constructs, it has a specialized tf.data.Iterator for iteration constructs. See the section on AutoGraph transformations for an overview. Also, the tf.data API can help implement generator patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7dee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def good_consume_next(iterator):\n",
    "  # This is ok, iterator is a tf.data.Iterator\n",
    "  tf.print(\"Value:\", next(iterator))\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "iterator = iter(ds)\n",
    "good_consume_next(iterator)\n",
    "good_consume_next(iterator)\n",
    "good_consume_next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ac37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae7891e7",
   "metadata": {},
   "source": [
    "### DON't understand Deleting tf.Variables between Function calls\n",
    "https://www.tensorflow.org/guide/function#deleting_tfvariables_between_function_calls\n",
    "\n",
    "### DON't understand All outputs of a tf.function must be return values\n",
    "https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802199eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28ee8611",
   "metadata": {},
   "source": [
    "### All outputs of a tf.function must be return values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f832b1",
   "metadata": {},
   "source": [
    "With the exception of tf.Variables, a tf.function must return all its outputs. Attempting to directly access any tensors from a function without going through return values causes \"leaks\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a160210",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None\n",
    "\n",
    "@tf.function\n",
    "def leaky_function(a):\n",
    "  global x\n",
    "  x = a + 1  # Bad - leaks local tensor\n",
    "  return a + 2\n",
    "\n",
    "correct_a = leaky_function(tf.constant(1))\n",
    "\n",
    "print(correct_a.numpy())  # Good - value obtained from function's returns\n",
    "with assert_raises(AttributeError):\n",
    "  x.numpy()  # Bad - tensor leaked from inside the function, cannot be used here\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def leaky_function(a):\n",
    "  global x\n",
    "  x = a + 1  # Bad - leaks local tensor\n",
    "  return x  # Good - uses local tensor\n",
    "\n",
    "correct_a = leaky_function(tf.constant(1))\n",
    "\n",
    "print(correct_a.numpy())  # Good - value obtained from function's returns\n",
    "with assert_raises(AttributeError):\n",
    "  x.numpy()  # Bad - tensor leaked from inside the function, cannot be used here\n",
    "print(x)\n",
    "\n",
    "@tf.function\n",
    "def captures_leaked_tensor(b):\n",
    "  b += x  # Bad - `x` is leaked from `leaky_function`\n",
    "  return b\n",
    "\n",
    "with assert_raises(TypeError):\n",
    "  captures_leaked_tensor(tf.constant(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "\n",
    "  def __init__(self):\n",
    "    self.field = None\n",
    "\n",
    "external_list = []\n",
    "external_object = MyClass()\n",
    "\n",
    "def leaky_function():\n",
    "  a = tf.constant(1)\n",
    "  external_list.append(a)  # Bad - leaks tensor\n",
    "  external_object.field = a  # Bad - leaks tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8f7f4",
   "metadata": {},
   "source": [
    "#### Depending on Python global and free variables\n",
    "Function creates a new ConcreteFunction when called with a new value of a Python argument. However, it does not do that for the Python closure, globals, or nonlocals of that Function. If their value changes in between calls to the Function, the Function will still use the values they had when it was traced. This is different from how regular Python functions work.\n",
    "\n",
    "For that reason, we recommend a functional programming style that uses arguments instead of closing over outer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b102f860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buggy: tf.Tensor(2, shape=(), dtype=int32)\n",
      "Correct: tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_add():\n",
    "  return 1 + foo\n",
    "\n",
    "@tf.function\n",
    "def recommended_add(foo):\n",
    "  return 1 + foo\n",
    "\n",
    "foo = 1\n",
    "print(\"Buggy:\", buggy_add())\n",
    "print(\"Correct:\", recommended_add(foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3cf6b070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating the value of `foo` to 100!\n",
      "Buggy: tf.Tensor(2, shape=(), dtype=int32)\n",
      "Correct: tf.Tensor(101, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Updating the value of `foo` to 100!\")\n",
    "foo = 100\n",
    "print(\"Buggy:\", buggy_add())  # Did not change!\n",
    "print(\"Correct:\", recommended_add(foo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adee26d",
   "metadata": {},
   "source": [
    "The recommendation to pass Python objects as arguments into tf.function has a number of known issues, that are expected to be fixed in the future. In general, you can rely on consistent tracing if you use a Python primitive or tf.nest-compatible structure as an argument or pass in a different instance of an object into a Function. However, Function will not create a new trace when you pass the same object and only change its attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6dc1d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(20.0, shape=(), dtype=float32)\n",
      "tf.Tensor(22.0, shape=(), dtype=float32)\n",
      "tf.Tensor(24.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class SimpleModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        # These values are *not* tf.Variables.\n",
    "        self.bias = 0.\n",
    "        self.weight = 2.\n",
    "\n",
    "@tf.function\n",
    "def evaluate(model, x):\n",
    "    print('Tracing!')\n",
    "    return model.weight * x + model.bias\n",
    "\n",
    "simple_model = SimpleModel()\n",
    "x = tf.constant(10.)\n",
    "print(evaluate(simple_model, x))\n",
    "x = tf.constant(11.)\n",
    "print(evaluate(simple_model, x))\n",
    "x = tf.constant(12.)\n",
    "print(evaluate(simple_model, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7a8a8217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x1867a67f940'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(simple_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a1b82256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding bias!\n",
      "tf.Tensor(24.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding bias!\")\n",
    "simple_model.bias += 5.0\n",
    "print(evaluate(simple_model, x))  # Didn't change :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c2f9579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x1867a67f940'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(id(simple_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e88063c",
   "metadata": {},
   "source": [
    "Using the same Function to evaluate the updated instance of the model will be buggy since the updated model has the same cache key as the original model.\n",
    "\n",
    "For that reason, we recommend that you write your Function to avoid depending on mutable object attributes or create new objects.\n",
    "\n",
    "If that is not possible, **one workaround is to make new Functions each time you modify your object to force retracing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2bf5f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(24.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, x):\n",
    "  return model.weight * x + model.bias\n",
    "\n",
    "new_model = SimpleModel()\n",
    "evaluate_no_bias = tf.function(evaluate).get_concrete_function(new_model, x)\n",
    "# Don't pass in `new_model`, `Function` already captured its state during tracing.\n",
    "print(evaluate_no_bias(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423bfc1",
   "metadata": {},
   "source": [
    "## I DON'T Understand why we do not need to pass new_model in the evaluate_with_bias...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a7bb383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding bias!\n",
      "tf.Tensor(29.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding bias!\")\n",
    "new_model.bias += 5.0\n",
    "# Create new Function and ConcreteFunction since you modified new_model.\n",
    "evaluate_with_bias = tf.function(evaluate).get_concrete_function(new_model, x)\n",
    "print(evaluate_with_bias(x)) # Don't pass in `new_model`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adfd227",
   "metadata": {},
   "source": [
    "As retracing can be expensive, you can use tf.Variables as object attributes, which can be mutated (but not changed, careful!) for a similar effect without needing a retrace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a91a6036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(24.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class BetterModel:\n",
    "\n",
    "  def __init__(self):\n",
    "    self.bias = tf.Variable(0.)\n",
    "    self.weight = tf.Variable(2.)\n",
    "\n",
    "@tf.function\n",
    "def evaluate(model, x):\n",
    "  return model.weight * x + model.bias\n",
    "\n",
    "better_model = BetterModel()\n",
    "print(evaluate(better_model, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b0fa3542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding bias!\n",
      "tf.Tensor(29.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding bias!\")\n",
    "better_model.bias.assign_add(5.0)  # Note: instead of better_model.bias += 5\n",
    "print(evaluate(better_model, x))  # This works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c1e1e",
   "metadata": {},
   "source": [
    "Function only supports singleton tf.Variables created once on the first call, and reused across subsequent function calls. The code snippet below would create a new tf.Variable in every function call, which results in a ValueError exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1d0bc76a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\SiFuBrO\\AppData\\Local\\Temp/ipykernel_6444/135690660.py:3 f  *\n        v = tf.Variable(1.0)\n    c:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:262 __call__  **\n        return cls._variable_v2_call(*args, **kwargs)\n    c:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:244 _variable_v2_call\n        return previous_getter(\n    c:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:730 invalid_creator_scope\n        raise ValueError(\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6444/135690660.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m-> 2941\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\SiFuBrO\\AppData\\Local\\Temp/ipykernel_6444/135690660.py:3 f  *\n        v = tf.Variable(1.0)\n    c:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:262 __call__  **\n        return cls._variable_v2_call(*args, **kwargs)\n    c:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:244 _variable_v2_call\n        return previous_getter(\n    c:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\users\\sifubro\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:730 invalid_creator_scope\n        raise ValueError(\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  v = tf.Variable(1.0)\n",
    "  return v\n",
    "\n",
    "\n",
    "f(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d46cc7",
   "metadata": {},
   "source": [
    "A common pattern used to work around this limitation is to start with a Python None value, then conditionally create the tf.Variable if the value is None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0771bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Count(tf.Module):\n",
    "  def __init__(self):\n",
    "    self.count = None\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self):\n",
    "    if self.count is None:\n",
    "      self.count = tf.Variable(0)\n",
    "    return self.count.assign_add(1)\n",
    "\n",
    "c = Count()\n",
    "print(c())\n",
    "print(c())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af963bf4",
   "metadata": {},
   "source": [
    "### ValueError: tf.function only supports singleton tf.Variables created on the first call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300616c1",
   "metadata": {},
   "source": [
    "#### Using with multiple Keras models\n",
    "You may also encounter ValueError: tf.function only supports singleton tf.Variables created on the first call. when passing different model instances to the same Function.\n",
    "\n",
    "This error occurs because Keras models (which do not have their input shape defined) and Keras layers create tf.Variabless when they are first called. You may be attempting to initialize those variables inside a Function, which has already been called. To avoid this error, try calling model.build(input_shape) to initialize all the weights before training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2c2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84eb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc6734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084ee22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f447cff1",
   "metadata": {},
   "source": [
    "### TIPS for @tf.function\n",
    "\n",
    "https://www.tensorflow.org/guide/intro_to_graphs#tffunction_best_practices\n",
    "\n",
    "- Debug in eager mode, then decorate with @tf.function\n",
    "- Toggle between eager and graph execution early and often with tf.config.run_functions_eagerly to pinpoint if/ when the two modes diverge.\n",
    "- Create tf.Variables outside the Python function and modify them on the inside. The same goes for objects that use tf.Variable, like keras.layers, keras.Models and tf.optimizers.\n",
    "- Avoid writing functions that depend on `outer Python variables` (https://www.tensorflow.org/guide/function#depending_on_python_global_and_free_variables), excluding tf.Variables and Keras objects.\n",
    "- Prefer to write functions which take tensors and other TensorFlow types as input. You can pass in other object types (https://www.tensorflow.org/guide/function#depending_on_python_objects) but be careful!\n",
    "- Don't rely on Python side effects like object mutation or list appends\n",
    "- tf.function works best with TensorFlow ops; NumPy and Python calls are converted to constants.\n",
    "- Include as much computation as possible under a tf.function to maximize the performance gain. For example, decorate a whole training step or the entire training loop.\n",
    "- `tf.function` is commonly used to speed up training loops, and you can learn more about it in Writing a training loop from scratch with Keras. (https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch#speeding_up_your_training_step_with_tffunction)\n",
    "-  how to set input specifications and use tensor arguments to avoid retracing (https://www.tensorflow.org/guide/function#controlling_retracing)\n",
    "- Specify input_signature in tf.function to limit tracing.\n",
    "- Specify a [None] dimension in tf.TensorSpec to allow for flexibility in trace reuse. Since TensorFlow matches tensors based on their shape, using a None dimension as a wildcard will allow Functions to reuse traces for variably-sized input.\n",
    "- Cast Python arguments to Tensors to reduce retracing\n",
    "- If you need to force retracing, create a new Function. Separate Function objects are guaranteed not to share traces.\n",
    "- tf.debugging.enable_check_numerics is an easy way to track down where NaNs and Inf are created\n",
    "- AutoGraph will convert some if \\<condition\\> statements into the equivalent tf.cond calls. This substitution is made if \\<condition\\> is a Tensor. Otherwise, the if statement is executed as a Python conditional.\n",
    "- for x in y: if y is a Tensor, convert to tf.while_loop. In the special case where y is a tf.data.Dataset, a combination of tf.data.Dataset ops are generated.\n",
    "- while \\<condition\\>: if \\<condition\\> is a Tensor, convert to tf.while_loop.\n",
    "- A common pitfall is to loop over Python/NumPy data within a tf.function. This loop will execute during the tracing process, adding a copy of your model to the tf.Graph for each iteration of the loop. If you want to wrap the entire training loop in tf.function, the safest way to do this is to wrap your data as a tf.data.Dataset so that AutoGraph will dynamically unroll the training loop.\n",
    "- A common pattern is to accumulate intermediate values from a loop. Normally, this is accomplished by appending to a Python list or adding entries to a Python dictionary. However, as these are Python side effects, they will not work as expected in a dynamically unrolled loop. Use tf.TensorArray to accumulate results from a dynamically unrolled loop.    \n",
    "- Side effects, like printing, appending to lists, and mutating globals, can behave unexpectedly inside a Function, sometimes executing twice or not all. They only happen the first time you call a Function with a set of inputs. Afterwards, the traced tf.Graph is reexecuted, without executing the Python code.\n",
    "- The general rule of thumb is to avoid relying on Python side effects in your logic and only use them to debug your traces. Otherwise, TensorFlow APIs like tf.data, tf.print, tf.summary, tf.Variable.assign, and tf.TensorArray are the best way to ensure your code will be executed by the TensorFlow runtime with each call.\n",
    "- **If you would like to execute Python code during each invocation of a Function, tf.py_function is an exit hatch. The drawback of tf.py_function is that it's not portable or particularly performant, cannot be saved with SavedModel, and does not work well in distributed (multi-GPU, TPU) setups. Also, since tf.py_function has to be wired into the graph, it casts all inputs/outputs to tensors.**\n",
    "- Changing Python global and free variables counts as a Python side effect, so it only happens during tracing.\n",
    "- You should avoid mutating containers like lists, dicts, other objects that live outside the Function. Instead, use arguments and TF objects. For example, the section \"Accumulating values in a loop\" has one example of how list-like operations can be implemented (with tf.TensorArray)\n",
    "- Many Python features, such as generators and iterators, rely on the Python runtime to keep track of state. In general, while these constructs work as expected in eager mode, they are examples of Python side effects and therefore only happen during tracing.\n",
    "- Just like how TensorFlow has a specialized tf.TensorArray for list constructs, it has a specialized tf.data.Iterator for iteration constructs. See the section on AutoGraph transformations for an overview. Also, the tf.data API can help implement generator patterns:\n",
    "- not use global inside tf.function to access variables outside. Just pass them as arguments (tensors????)\n",
    "- Do NOT mutate an external Python collection or an object from tf.function\n",
    "- Function creates a new ConcreteFunction when called with a new value of a Python argument. However, it does not do that for the Python closure, globals, or nonlocals of that Function. If their value changes in between calls to the Function, the Function will still use the values they had when it was traced. This is different from how regular Python functions work. For that reason, we recommend a functional programming style that uses arguments instead of closing over outer names.\n",
    "- The recommendation to pass Python objects as arguments into tf.function has a number of known issues, that are expected to be fixed in the future. In general, you can rely on consistent tracing if you use a Python primitive or tf.nest-compatible structure as an argument or pass in a different instance of an object into a Function. However, Function will not create a new trace when you pass the same object and only change its attributes\n",
    "- we recommend that you write your Function to avoid depending on mutable object attributes or create new objects.If that is not possible, one workaround is to make new Functions each time you modify your object to force retracing\n",
    "- Function only supports singleton tf.Variables created once on the first call, and reused across subsequent function calls. The code snippet below would create a new tf.Variable in every function call, which results in a ValueError exception.A common pattern used to work around this limitation is to start with a Python None value, then conditionally create the tf.Variable if the value is None (https://www.tensorflow.org/guide/function#creating_tfvariables)\n",
    "- \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**RULES OS TRACING**\n",
    "- https://www.tensorflow.org/guide/function#rules_of_tracing\n",
    "\n",
    "see also\n",
    "\n",
    "- https://stackoverflow.com/questions/59847045/should-i-use-tf-function-for-all-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfaffce",
   "metadata": {},
   "source": [
    "- A tf.Graph is the raw, language-agnostic, portable representation of a TensorFlow computation.\n",
    "- A ConcreteFunction wraps a tf.Graph.\n",
    "- A Function manages a cache of ConcreteFunctions and picks the right one for your inputs.\n",
    "- tf.function wraps a Python function, returning a Function object.\n",
    "- Tracing creates a tf.Graph and wraps it in a ConcreteFunction, also known as a trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb172f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e651bb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ad0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "709e98a2",
   "metadata": {},
   "source": [
    "### !TODO! See Better performance with tf.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738ba41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537492f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7494825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a52ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee36b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb926c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cecaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676c34c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74d386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dcbc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d303913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b239af93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573845b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f8b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413adf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7702e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02bcb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d9502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1e41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a42090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f88ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ef78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6edd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa69fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c14a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abdaa97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c116b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33ae24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ea76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67dc429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10397db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02b58e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
