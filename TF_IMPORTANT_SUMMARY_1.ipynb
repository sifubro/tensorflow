{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78cf78ba",
   "metadata": {},
   "source": [
    "### <ins> Download and untar dataset from url </ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134a8d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821683a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d86b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5a7bd61",
   "metadata": {},
   "source": [
    "### <ins> Number of images in directory </ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a95e5",
   "metadata": {},
   "source": [
    "### <ins> View an image from directory </ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "# open a file also to view\n",
    "PIL.Image.open(str(roses[0]))\n",
    "#PIL.Image.open(str(roses[1])) etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb321b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d18ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dfa4782",
   "metadata": {},
   "source": [
    "### <ins> Load data from disk </ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce8992",
   "metadata": {},
   "source": [
    "#### (1) tf.keras.utils.image_dataset_from_directory\n",
    "(https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory)\n",
    "\n",
    "Generates a tf.data.Dataset from image files in a directory.\n",
    "\n",
    "**Comments:**\n",
    "- should specify `image_size`: Size to resize images to after they are read from disk. Defaults to (256, 256). Since the pipeline processes batches of images that must all have the same size, this must be provided.\n",
    "- `interpolation`: String, the interpolation method used when resizing images. Defaults to bilinear. Supports bilinear, nearest, bicubic, area, lanczos3, lanczos5, gaussian, mitchellcubic.\n",
    "- `crop_to_aspect_ratio`: \tIf True, resize the images without aspect ratio distortion. When the original aspect ratio differs from the target aspect ratio, the output image will be cropped so as to return the largest possible window in the image (of size image_size) that matches the target aspect ratio. By default (crop_to_aspect_ratio=False), aspect ratio may not be preserved.\n",
    "- `color_mode`: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". Whether the images will be converted to have 1, 3, or 4 channels.\n",
    "- `label_mode`: \n",
    "    - 'int': means that the labels are encoded as integers (e.g. for `sparse_categorical_crossentropy` loss). 'categorical' means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).\n",
    "    - 'binary' means that the labels (there can be only 2) are encoded as float32 scalars with values 0 or 1 (e.g. for binary_crossentropy).\n",
    "    - None (no labels).\n",
    "- `validation_split`: we could use this to set a valid set. Hence the original folder should contain all images\n",
    "- `subset` (**Not sure!**): One of \"training\" or \"validation\". Only used if validation_split is set. Maybe this is used to control which dataset to load? Should we split images in separate folders (train validation or not????).\n",
    "- `follow_links`: Whether to visits subdirectories pointed to by symlinks. Defaults to False\n",
    "\n",
    "Returns: A tf.data.Dataset object. It yields float32 tensors (batch_size, image_size[0], image_size[1], num_channels) If label_mode is None, Otherwise, it yields a tuple (images, labels), where images has shape (batch_size, image_size[0], image_size[1], num_channels), and labels follows the format below.\n",
    "\n",
    "- if label_mode is int, the labels are an int32 tensor of shape (batch_size,).\n",
    "- if label_mode is binary, the labels are a float32 tensor of 1s and 0s of shape (batch_size, 1).\n",
    "- if label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes), representing a one-hot encoding of the class index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab23376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6da434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bb9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd94acf8",
   "metadata": {},
   "source": [
    "### <ins> Apply transformations to the dataset </ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# from keras.engine import base_layer\n",
    "# from keras.engine import base_preprocessing_layer\n",
    "\n",
    "from tensorflow.python.keras.engine import base_layer\n",
    "from tensorflow.python.keras.engine import base_preprocessing_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Rescaling\n",
    "\n",
    "normalization_layer = Rescaling(1./255) # [0,1] normalization\n",
    "#normalization_layer = Rescaling(1./127.5, offset=-1)  # [-1,1] normalization\n",
    "\n",
    "#normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "#tf.keras.layers.Rescaling(1./127.5, offset=-1)  # [-1,1] normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112d91e8",
   "metadata": {},
   "source": [
    "### dataset.map(map_func)\n",
    "This transformation applies map_func to each element of this dataset, and returns a new dataset containing the transformed elements, in the same order as they appeared in the input. map_func can be used to change both the values and the structure of a dataset's elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ed9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization_layer = tf.keras.layers.Rescaling(1./255) #[0,1] normalization\n",
    "# # tf.keras.layers.Rescaling(1./127.5, offset=-1)  # [-1,1] normalization\n",
    "\n",
    "# normalized_ds_tr = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "# normalized_ds_val = val_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## see results of normalization\n",
    "# image_batch, labels_batch = next(iter(normalized_ds))\n",
    "# first_image = image_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3dadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46146c17",
   "metadata": {},
   "source": [
    "### Convert dataset into numpy iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "\n",
    "dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ac968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc218620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331d361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e6da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b109f91",
   "metadata": {},
   "source": [
    "### <ins> Configure dataset for performance </ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd5d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3000ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce36ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24699b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a16b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9794b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "<ins> </ins>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
